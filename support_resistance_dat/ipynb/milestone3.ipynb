{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter as smooth\n",
    "scanning_window=5\n",
    "# this function returns the local maxima and the minima\n",
    "# Input:\n",
    "# ltp: a panda dataframe with column 'Date_Time' and 'Close'\n",
    "# n: is the width of window to examine max and min, should be odd and greater than 3\n",
    "# Return:\n",
    "# max: the local maxima among the n of its neigbours\n",
    "# min: the local minima among the n of its neigbours\n",
    "# min and max are list of tuples in shape [(date,price),(date,price),(),(),...]\n",
    "def max_min(ltp,n):\n",
    "    assert n%2==1, \"n should be an odd number greater than 3\"\n",
    "    ltp_sm = smooth(ltp['Close'],n,3)\n",
    "    max_points = []\n",
    "    min_points = []\n",
    "    ltp_dif = np.zeros(ltp_sm.shape[0]-1)\n",
    "    ltp_dif = ltp_sm[1:]-ltp_sm[:-1]\n",
    "    center = int((n-1)/2)\n",
    "    for i in range(ltp_dif.shape[0]-n+2):\n",
    "        window = ltp_dif[i:i+n-1]\n",
    "        front = window[:center]\n",
    "        back = window[center:]\n",
    "        s_first = np.sum(front<0)\n",
    "        s_back = np.sum(back>0)\n",
    "        r_first = np.sum(front>0)\n",
    "        r_back = np.sum(back<0)\n",
    "        if(r_first == center and r_back == center):\n",
    "            max_points.append((ltp['Date_Time'][i+center],ltp['Close'][i+center]))\n",
    "            # print(ltp[i+center])\n",
    "        if(s_first== center and s_back== center):\n",
    "            min_points.append((ltp['Date_Time'][i+center],ltp['Close'][i+center]))\n",
    "            # print(ltp[i+center])\n",
    "    return max_points,min_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_threshold = 0.8\n",
    "# this function find the cluster of a series of data according to price and threshold given\n",
    "# Input:\n",
    "# pairs: [(data,price)(date,price),...]\n",
    "# threshold: price within this range will be clustered together\n",
    "# Return:\n",
    "# groups of cluster in shape [[(date,price),(date,price),()...],[],...]\n",
    "# each cluster is sorted in date\n",
    "# return is in list of list of tuple, each list a cluste\n",
    "def cluster(pairs, threshold = 0.8):\n",
    "    # first sort the given pairs according to price\n",
    "    paris = sorted(pairs, key=lambda x: x[1])\n",
    "    groups = []\n",
    "    current = []\n",
    "    # the smallest value in the current group\n",
    "    vl = 0\n",
    "    for pair in pairs:\n",
    "        if not current:\n",
    "            current.append(pair)\n",
    "            vl = pair[1]\n",
    "        elif pair[1]-vl<threshold:\n",
    "            current.append(pair)\n",
    "        else:\n",
    "            if len(current)>1:\n",
    "                groups.append(sorted(current))\n",
    "            vl = pair[1]\n",
    "            current = [pair]\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transfer back to numpy array for easiness to index\n",
    "they are tuple in prior steps because np array only support\n",
    "one dtype. String and float can not co-exist. For sorting and\n",
    "clustering purposes, they have to be converted to tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function produce support, resistance lines out of original data and the clustted group\n",
    "# In a group, if the line represented by the group not intersected by data in the group,\n",
    "# or more than or equal to two points on a line is not disturbed by the intersection, then the line is preserved\n",
    "# Input:\n",
    "# group_list: in the form [[(),(),()],[(),()],...]\n",
    "# data:  the original pandas dataframe. It shall be converted into matrix inside the function\n",
    "# support: is a qualitative variable, True for support and false for demand\n",
    "# Return:\n",
    "# group of line in the shape of [pd.dataframe['Date_Time','Support/Resistance'], pd.dataframe[],...]\n",
    "# the second row of each dataframe in group is the same\n",
    "\n",
    "def into_arr(group_list,data,support=True):\n",
    "    groups=[]\n",
    "    for group in group_list:\n",
    "        # extract date, price\n",
    "        date = np.asarray(group)[:,0]\n",
    "        price = np.asarray(group)[:,1]\n",
    "        price = price.astype(np.float)\n",
    "        # form line, calculate when line start and stop\n",
    "        average_price = np.average(price)\n",
    "        mask_after_first = data[:,0] > date[0]\n",
    "        if support:\n",
    "            break_through = data[:,1] < np.min(price)\n",
    "        else:\n",
    "            break_through = data[:,1] > np.max(price)\n",
    "        break_through = np.bitwise_and(break_through,mask_after_first)\n",
    "                    \n",
    "        # fix the intersection and eliminate the fake lines\n",
    "        slicing_date = date\n",
    "#         print(\"the date series is\")\n",
    "#         print(slicing_date)\n",
    "        break_times = np.array([])\n",
    "        if np.sum(np.argwhere(break_through))>0:\n",
    "            break_times = data[:,0][np.argwhere(break_through)]\n",
    "#         print(\"the break time\")\n",
    "#         print(break_times)\n",
    "        for break_time in break_times:\n",
    "            num_before_break = np.sum(slicing_date<break_time)\n",
    "            # two or more times before break through, form a line\n",
    "            if num_before_break > 1:\n",
    "                # the last point before the break point\n",
    "                last_point_before_break = np.argwhere(slicing_date < break_time)[-1][0]\n",
    "#                 print(last_point_before_break)\n",
    "#                 print(slicing_date)\n",
    "                # last_date = slicing_date[last_point_before_break]\n",
    "                date_range = pd.date_range(slicing_date[0],break_time[0])\n",
    "                df = pd.DataFrame({'support':[average_price for i in range(date_range.shape[0])]},index=date_range)\n",
    "                if(not support):\n",
    "                    df.rename(columns={'support':'resistance'}, inplace=True)\n",
    "                groups.append(df)\n",
    "#                 if last_point_before_break + 2 > slicing_date.shape[0]:\n",
    "#                     slicing_date = \n",
    "#                     break\n",
    "                if slicing_date.shape[0] > last_point_before_break+1:\n",
    "                    slicing_date = slicing_date[last_point_before_break+1:]\n",
    "                else:\n",
    "                    slicing_date = np.array([])\n",
    "            # only one single point before break through, discard\n",
    "            elif slicing_date.shape[0] > 1:\n",
    "                if num_before_break == 1:\n",
    "                    slicing_date = slicing_date[1:]\n",
    "            # no points before break through\n",
    "            else:\n",
    "                break               \n",
    "        # if break_time runs out but slicing_date stills exist,\n",
    "        # breaks in the middle, and exist until the last points\n",
    "        # or no break points at all\n",
    "        if slicing_date.shape[0]>1:\n",
    "            last_date = data[:,0][-1]\n",
    "            date_range = pd.date_range(slicing_date[0],last_date)\n",
    "            df = pd.DataFrame({'support':[average_price for i in range(date_range.shape[0])]},index=date_range)\n",
    "            if(not support):\n",
    "                df.rename(columns={'support':'resistance'}, inplace=True)\n",
    "            groups.append(df)\n",
    "    return groups\n",
    "# the algorithm uses a break-point by break-point approach to check whether a group of min/max points is valided.\n",
    "# for each breakpoint, if it intersectes as of time with the current group, then if there are two or more points\n",
    "# before the intersected breakthough, the segmented lines should be kept, otherwise discarded. Then we check the\n",
    "# next breaktime. Notice that the obvious dawback of this approach is its high computational intensity, namely all\n",
    "# points within the break_through series, which could be very long has to be checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the support and resistance with the original dataframe, and possibly plot it out\n",
    "# Input:\n",
    "# data: original pandas dataframe\n",
    "# support: the support group in the shape [pd.dataframe['Date_Time','Support/Resistance'], pd.dataframe[],...]\n",
    "# resistance: the resistant group in the shape [pd.dataframe['Date_Time','Support/Resistance'], pd.dataframe[],...]\n",
    "# render: whether or not to plot out the data\n",
    "# Return:\n",
    "# the merged data containing Date_time, close, and the subsequent support and resistance columns\n",
    "# NaN will be filled in when the support line or resistance line does not fully covers the whole time frame\n",
    "def plot_sr(data,support_lines,resist_lines,render):\n",
    "    color=['b']\n",
    "    counter = 1\n",
    "    for support in support_lines:\n",
    "        support.rename(columns={'support':'support'+str(counter)}, inplace=True)\n",
    "        data = data.merge(i,how='left',left_on='Date_Time',right_index=True)\n",
    "        color.append('g')\n",
    "        counter = counter+1\n",
    "    counter = 1\n",
    "    for resist in resist_lines:\n",
    "        resist.rename(columns={'resistance':'resistance'+str(counter)}, inplace=True)\n",
    "        data = data.merge(i,how='left',left_on='Date_Time',right_index=True)\n",
    "        color.append('r')\n",
    "        counter = counter+1\n",
    "    if render:\n",
    "        data.plot(x='Date_Time',legend=False,color = color)\n",
    "        plt.show()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser(description = 'input arguments')\n",
    "    parser.add_argument('data_file',type=str)\n",
    "    parser.add_argument('--check_all',action='store_false',\n",
    "                        help='supply support resistance to all data from the source, default false')\n",
    "    parser.add_argument('--start',type=int,default=0,\n",
    "                        help='start point of checking the data, will be overriden if --check_all=True')\n",
    "    parser.add_argument('--end',type=int,default=500,\n",
    "                        help='end point of checking the data, will be overriden if --check_all=True')\n",
    "    parser.add_argument('--cluster_threshold',type=int,default=0.8,\n",
    "                        help='the threshold within which data of each price is grouped together')\n",
    "    parser.add_argument('--save_result',action='store_false',help='switch for saving the data to filename_sr.csv')\n",
    "    parser.add_argument('--render',action='store_true',help='plot support and resistance before storing')\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    if os.path.exists(args.data_file):\n",
    "        # read in the Date, Time, Close column of data\n",
    "        date_parser = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "        tpdata = pd.read_table(args.data_file,delimiter=',',header=0,parse_dates=[['Date','Time']],usecols=['Date','Time','Close'])\n",
    "        \n",
    "        if not args.check_all:\n",
    "            assert args.start > -1,'the start index has to be positive'\n",
    "            assert args.start < len(tpdata.shape), 'the start index has to be smaller than length of data %d'%len(tpdata.shape)\n",
    "            assert args.end > 0,'the end index has to be positive'\n",
    "            assert args.end < len(tpdata.shape), 'the end index has to be smaller than length of data %d'%len(tpdata.shape)\n",
    "            tpdata = tpdata[args.start:args.end]\n",
    "            \n",
    "        # find the local max and min\n",
    "        maxima,minima = max_min(tpdata,scanning_window)\n",
    "        # cluster the max and min to form groups\n",
    "        max_group = cluster(maxima,args.cluster_threshold)\n",
    "        min_group = cluster(minima,args.cluster_threshold)\n",
    "        # generate the support and resistance line group\n",
    "        support = into_arr(min_group,tpdata.as_matrix(),True)\n",
    "        resistance = into_arr(max_group,tpdata.as_matrix(),False)\n",
    "        # merge the full data with support and resistance\n",
    "        # the new support and resistance lines shall become extra columns\n",
    "        full_data =  pd.read_table(args.data_file,delimiter=',',header=0,parse_dates=[['Date','Time']])\n",
    "        if not args.check_all:\n",
    "            full_data = full_data[args.start:args.end]\n",
    "        close_sr = plot_sr(full_data,support,resistance,args.render).set_index('Date_Time')\n",
    "        if args.save_result:\n",
    "            # save the cleansed data into new csv data\n",
    "            destination_file = os.path.splitext(args.data_file)[0]+'_sr.csv'\n",
    "            close_sr.to_csv(destination_file)\n",
    "            print('the data with support and resistance added is saved at %s' %destination_file)\n",
    "        print('support and resistance founded')\n",
    "    else:\n",
    "        print(\"data_file not found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--check_all] [--start START] [--end END]\n",
      "                             [--cluster_threshold CLUSTER_THRESHOLD]\n",
      "                             [--save_result] [--render]\n",
      "                             data_file\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elessar/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2870: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
